from argparse import ArgumentParser
from pathlib import Path
from datasets import load_dataset
import unicodedata
import pandas as pd

parser = ArgumentParser()
parser.add_argument("-e", "--export", default=None, type=Path)
args = parser.parse_args()

test_langs = [
    'akk',
    'hy',
    'cy',
    'no',
    'orv',
    'en',
    'sq',
    'fr',
    # 'qhe',
    'sl',
    'gub',
    'kmr',
    'it',
    'tr',
    'fi',
    'id',
    'uk',
    'nl',
    'pl',
    'pt',
    'kk',
    'la',
    'fro',
    'es',
    'bxr',
    'urb',
    'ko',
    'et',
    'hr',
    'got',
    # 'swl',
    'gsw',
    'aii',
    'sme',
    'pcm',
    'de',
    'lv',
    'zh',
    'tl',
    'bm',
    'lt',
    'gl',
    'vi',
    # 'am',
    'el',
    'ca',
    # 'soj',
    'sv',
    # 'ess',
    'ru',
    'cs',
    # 'bej',
    'myv',
    'bho',
    'th',
    'mr',
    'eu',
    'sk',
    'quc',
    'yo',
    'wbp',
    'nds',
    'ta',
    'mt',
    'grc',
    'is',
    'gun',
    'ur',
    'ro',
    'fa',
    'apu',
    'ja',
    'hu',
    'hi',
    'lzh',
    'koi',
    'fo',
    'sa',
    'olo',
    'ar',
    'wo',
    'bg',
    'aqz',
    'mpu',
    'xnr',
    'br',
    'te',
    'yue',
    # 'qtd',
    'cu',
    'krl',
    'hsb',
    'da',
    'ajp',
    'kpv',
    'ga',
    'nyq',
    # 'qfn',
    'myu',
    'gv',
    'sms',
    'af',
    'otk',
    'tpn',
    'be',
    # 'cop',
    'sr',
    'mdf',
    'hyw',
    'gd',
    'kfm',
    'he',
    'ug',
    'ckt',
]

lang_names = {
    'akk': 'Akkadian',
    'hy': 'Armenian',
    'cy': 'Welsh',
    'no': 'Norwegian',
    'orv': 'Old_East_Slavic',
    'en': 'English',
    'sq': 'Albanian',
    'fr': 'French',
    'qhe': 'Hindi_English',
    'sl': 'Slovenian',
    'gub': 'Guajajara',
    'kmr': 'Kurmanji',
    'it': 'Italian',
    'tr': 'Turkish',
    'fi': 'Finnish',
    'id': 'Indonesian',
    'uk': 'Ukrainian',
    'nl': 'Dutch',
    'pl': 'Polish',
    'pt': 'Portuguese',
    'kk': 'Kazakh',
    'la': 'Latin',
    'fro': 'Old_French',
    'es': 'Spanish',
    'bxr': 'Buryat',
    'urb': 'Kaapor',
    'ko': 'Korean',
    'et': 'Estonian',
    'hr': 'Croatian',
    'got': 'Gothic',
    'swl': 'Swedish_Sign_Language',
    'gsw': 'Swiss_German',
    'aii': 'Assyrian',
    'sme': 'North_Sami',
    'pcm': 'Naija',
    'de': 'German',
    'lv': 'Latvian',
    'zh': 'Chinese',
    'tl': 'Tagalog',
    'bm': 'Bambara',
    'lt': 'Lithuanian',
    'gl': 'Galician',
    'vi': 'Vietnamese',
    'am': 'Amharic',
    'el': 'Greek',
    'ca': 'Catalan',
    'soj': 'Soi',
    'sv': 'Swedish',
    'ess': 'Yupik',
    'ru': 'Russian',
    'cs': 'Czech',
    'bej': 'Beja',
    'myv': 'Erzya',
    'bho': 'Bhojpuri',
    'th': 'Thai',
    'mr': 'Marathi',
    'eu': 'Basque',
    'sk': 'Slovak',
    'quc': 'Kiche',
    'yo': 'Yoruba',
    'wbp': 'Warlpiri',
    'nds': 'Low_Saxon',
    'ta': 'Tamil',
    'mt': 'Maltese',
    'grc': 'Ancient_Greek',
    'is': 'Icelandic',
    'gun': 'Mbya_Guarani',
    'ur': 'Urdu',
    'ro': 'Romanian',
    'fa': 'Persian',
    'apu': 'Apurina',
    'ja': 'Japanese',
    'hu': 'Hungarian',
    'hi': 'Hindi',
    'lzh': 'Classical_Chinese',
    'koi': 'Komi_Permyak',
    'fo': 'Faroese',
    'sa': 'Sanskrit',
    'olo': 'Livvi',
    'ar': 'Arabic',
    'wo': 'Wolof',
    'bg': 'Bulgarian',
    'aqz': 'Akuntsu',
    'mpu': 'Makurap',
    'xnr': 'Kangri',
    'br': 'Breton',
    'te': 'Telugu',
    'yue': 'Cantonese',
    'qtd': 'Turkish_German',
    'cu': 'Old_Church_Slavonic',
    'krl': 'Karelian',
    'hsb': 'Upper_Sorbian',
    'da': 'Danish',
    'ajp': 'South_Levantine_Arabic',
    'kpv': 'Komi_Zyrian',
    'ga': 'Irish',
    'nyq': 'Nayini',
    'qfn': 'Frisian_Dutch',
    'myu': 'Munduruku',
    'gv': 'Manx',
    'sms': 'Skolt_Sami',
    'af': 'Afrikaans',
    'otk': 'Old_Turkish',
    'tpn': 'Tupinamba',
    'be': 'Belarusian',
    'cop': 'Coptic',
    'sr': 'Serbian',
    'mdf': 'Moksha',
    'hyw': 'Western_Armenian',
    'gd': 'Scottish_Gaelic',
    'kfm': 'Khunsari',
    'he': 'Hebrew',
    'ug': 'Uyghur',
    'ckt': 'Chukchi',
}


def get_script(txt):
    scripts = []
    try:
        for c in txt:
            s = unicodedata.name(c).split()
            if s[0] == "OLD":
                s = s[0] + " " + s[1]
            else:
                s = s[0]
            scripts.append(s)
    except ValueError:
        pass

    scripts = [
        s for s in scripts if s not in {
            "FULL",
            "LEFT-POINTING",
            "RIGHT-POINTING",
            "RIGHT",
            "LEFT",
            "DIGIT",
            "QUOTATION",
            "COMMA",
            "COLON",
            "HYPHEN-MINUS",
            'GREATER-THAN',
            'SOLIDUS',
            'AMPERSAND',
            'PLUS',
            'APOSTROPHE',
            'LESS-THAN',
            'VERTICAL',
            'EQUALS',
            'EXCLAMATION',
            'TILDE',
            'QUESTION',
            'NUMBER',
            'DOLLAR',
            'IDEOGRAPHIC',
            'FULLWIDTH',
            'EM',
            'PERCENT',
            'MIDDLE',
            'LOW',
            'POUND',
            'MIDLINE',
            'HORIZONTAL',
            'BULLET',
            'BOX',
            'SEMICOLON',
            'SPACE',
            'MODIFIER',
            'INVERTED',
            'COMBINING',
            'ACUTE',
            'RIGHT-TO-LEFT',
            'TELEVISION',
            'SEEDLING',
            'ORANGE',
            'HEADPHONE',
            'EVERGREEN',
            'BLACK',
            'NEUTRAL',
            'SIGN',
            'RELIEVED',
            'YELLOW',
            'HIGH',
            'TEACUP',
            'GRINNING',
            'WHITE',
            'HOT',
            'FIRE',
            'WINKING',
            'OPEN',
            'ROUND',
            'UPWARDS',
            'ROLLING',
            'SMILING',
            'FALLEN',
            'HEAVY',
            'VARIATION',
            'COMMERCIAL',
            'EMOJI',
            'MOBILE',
            'DOUBLE',
            'SPARKLES',
            'NUMERO',
            'EN',
            'SPLASHING',
            'CLAPPER',
            'FACE',
            'VICTORY',
            'RUNNER',
        }
    ]
    unique_scripts = [s for s in sorted(set(scripts)) if scripts.count(s) > len(scripts) * 0.2]
    if len(unique_scripts) == 1:
        return unique_scripts[0].lower()

    for script in unique_scripts:
        n = scripts.count(script)
        if n >= 0.95 * len(scripts):
            return script.lower()

    if unique_scripts == ["CJK", "HIRAGANA"]:
        return "kana"
    print("AMBIGUOUS:", unique_scripts)
    input()


lines = []
for lang_id in (test_langs):
    d = load_dataset("./datasets/udpos28", lang_id, split="test")
    t = "".join([y for x in d["tokens"] for y in x])
    s = get_script(t)
    if s == "cjk":
        s = "chinese"

    lang_name = lang_names[lang_id].replace('_', ' ')
    print(f"{lang_id:<5} {lang_name:<20} {s}")
    lines.append((lang_id, lang_name, s))

df = pd.DataFrame(lines, columns=["language_id", "language", "script"])
print(df.script.value_counts())
if args.export:
    df.to_csv(args.export)
